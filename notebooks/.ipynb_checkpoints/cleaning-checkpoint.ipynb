{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bd400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/usuari/miniconda3/envs/ironhack/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/usuari/miniconda3/envs/ironhack/lib/python3.11/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/usuari/miniconda3/envs/ironhack/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: gender-guesser in /Users/usuari/miniconda3/envs/ironhack/lib/python3.11/site-packages (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "!pip install bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import spacy\n",
    "!pip install gender-guesser\n",
    "import gender_guesser.detector as gender_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fdaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_before_webscraping():\n",
    "    \n",
    "    # I explain here the steps previous to the web scraping process.\n",
    "    \n",
    "    # Import csv file.\n",
    "    books = pd.read_csv(\"/Users/usuari/Desktop/Ironhack/BOOTCAMP/projects/project-II/Data/books_genres.csv\",on_bad_lines='skip')\n",
    "    \n",
    "    # Rename columns\n",
    "    books = books.rename(columns={'  num_pages': 'num_pages'})\n",
    "    books.columns = [i.lower().replace(\" \", \"_\") for i in books.columns]\n",
    "    \n",
    "    # Dropping two useless columns\n",
    "    books.drop(['isbn13', 'isbn'], axis=1, inplace=True)\n",
    "    \n",
    "    # Creating a new column\n",
    "    pattern = r'(\\d{4})'\n",
    "    books['years'] = books['publication_date'].str.extract(pattern)\n",
    "    \n",
    "    def author_name(string):\n",
    "        standardized_name = re.sub(r'\\s+', '_', string)\n",
    "        # Add a period (.) before each uppercase letter (except the first one and spaces)\n",
    "        standardized_name = re.sub(r'(?<=[a-zA-Z])(?=[A-Z])', '._', standardized_name)\n",
    "        # Add a period (.) before each uppercase letter following a period\n",
    "        standardized_name = re.sub(r'\\.(?=[A-Z])', '._', standardized_name)\n",
    "        \n",
    "        if standardized_name == 'Newt_Scamander/J._K._Rowling':\n",
    "            return 'J._K._Rowling'\n",
    "        else:\n",
    "            return standardized_name\n",
    "    \n",
    "    # Applying the function written above\n",
    "    books['author'] = books['author'].apply(author_name)\n",
    "    \n",
    "    # Creating a new dataframe\n",
    "    book_author = books[['title', 'author']]\n",
    "    \n",
    "    # From this new dataframe I'm going to create another one, in which the rows with multiple authors only keep the first author.\n",
    "\n",
    "    new_rows = []\n",
    "\n",
    "    for index, row in book_author.iterrows():\n",
    "        authors = row['author'].split('/')\n",
    "        if len(authors) > 1:\n",
    "        # If there are multiple authors, I keep only the first author\n",
    "            first_author = authors[0]\n",
    "            new_row = {'title': row['title'], 'author': first_author}\n",
    "            new_rows.append(new_row)\n",
    "        else:\n",
    "        # If there is only one author, keep the original row\n",
    "            new_rows.append({'title': row['title'], 'author': row['author']})\n",
    "\n",
    "    # The new DataFrame with the updated rows\n",
    "    new_books = pd.DataFrame(new_rows)\n",
    "\n",
    "    # Reset the index\n",
    "    new_books.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #I add the columns from the original dataframe that interest me.\n",
    "\n",
    "    new_books['average_rating'] = books['average_rating']\n",
    "    new_books['language_code'] = books['language_code']\n",
    "    new_books['num-pages'] = books['num_pages']\n",
    "    new_books['ratings_count'] = books['ratings_count']\n",
    "    new_books['text_reviews_count'] = books['text_reviews_count']\n",
    "    new_books['publisher'] = books['publisher']\n",
    "    new_books['genres'] = books['genres']\n",
    "    new_books['years'] = books['years']\n",
    "    \n",
    "    # I create three empty columns in this new dataframe (which I will fill afterwards with web scraping data from wikipedia): \n",
    "    # 'author_birthplace', 'author_birthdate', 'author_gender'.\n",
    "\n",
    "    new_books['author_birthplace'] = None\n",
    "    new_books['author_birthdate'] = None\n",
    "    new_books['author_gender'] = None\n",
    "    \n",
    "    # I'm going to drop the names of the authors that are not in a latin alphabet.\n",
    "\n",
    "    latin_pattern = re.compile(r'^[a-zA-Z_. ]+$')  \n",
    "    lat_books = new_books[new_books['author'].str.match(latin_pattern)]\n",
    "    \n",
    "    # I'm going to drop the rows in which the column of 'ratings_count' are less than 1000, because I want to analyze the most rated books.\n",
    "\n",
    "    lat_books = lat_books[lat_books['ratings_count'] >= 1000]\n",
    "\n",
    "    # I want to focuse on novels, so I'm going to drop the short stories:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Short Stories')].index)\n",
    "\n",
    "    # I also want to focuse on Fiction:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Nonfiction')].index)\n",
    "\n",
    "    # I want to exclude comics and manga:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Comics')].index)\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Manga')].index)\n",
    "\n",
    "    #I'm goint to exclude Poetry as well:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Poetry')].index)\n",
    "\n",
    "    # and I'll exclude plays:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Plays')].index)\n",
    "\n",
    "    #I'm also Childrens' Animal and Picture Books:\n",
    "\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Animals')].index)\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['genres'].str.contains('Picture Books')].index)\n",
    "\n",
    "    # I don't want any set but individual books:\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['title'].str.contains('Set')].index)\n",
    "    lat_books = lat_books.drop(lat_books[lat_books['title'].str.contains('Collection')].index)\n",
    "    \n",
    "    def clean_genres(string):\n",
    "        if 'Horror' in string:\n",
    "            return 'Horror'\n",
    "        elif 'Science Fiction' and 'Fantasy' in string:\n",
    "            return 'Fantasy & Science Fiction'\n",
    "        elif 'Fiction' and 'Historical' in string:\n",
    "            return 'Historical novel'\n",
    "        elif 'Fiction' and 'Thriller' in string:\n",
    "            return 'Thriller'\n",
    "        elif '20th Century' in string:\n",
    "            return '20th Century Fiction'\n",
    "        elif 'Classics' in string:\n",
    "            return 'Classics'\n",
    "        elif 'Science Fiction' in string:\n",
    "            return 'Science Fiction'\n",
    "        elif 'Contemporary' in string:\n",
    "            return 'Contemporary Fiction'\n",
    "        elif 'Erotica' in string:\n",
    "            return 'Erotica'\n",
    "        elif 'European' and 'Fiction':\n",
    "            return 'European Literature'\n",
    "        else:\n",
    "            return string\n",
    "    \n",
    "    # I apply the function above to clean book genres:\n",
    "    lat_books['genres'] = lat_books['genres'].apply(clean_genres)\n",
    "   \n",
    "    return lat_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa8e668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>language_code</th>\n",
       "      <th>num-pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>years</th>\n",
       "      <th>author_birthplace</th>\n",
       "      <th>author_birthdate</th>\n",
       "      <th>author_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>J._K._Rowling</td>\n",
       "      <td>4.57</td>\n",
       "      <td>eng</td>\n",
       "      <td>652</td>\n",
       "      <td>2095690</td>\n",
       "      <td>27591</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2006</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>J._K._Rowling</td>\n",
       "      <td>4.49</td>\n",
       "      <td>eng</td>\n",
       "      <td>870</td>\n",
       "      <td>2153167</td>\n",
       "      <td>29221</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2004</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Harry...</td>\n",
       "      <td>J._K._Rowling</td>\n",
       "      <td>4.42</td>\n",
       "      <td>eng</td>\n",
       "      <td>352</td>\n",
       "      <td>6333</td>\n",
       "      <td>244</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2003</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Harr...</td>\n",
       "      <td>J._K._Rowling</td>\n",
       "      <td>4.56</td>\n",
       "      <td>eng</td>\n",
       "      <td>435</td>\n",
       "      <td>2339585</td>\n",
       "      <td>36325</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2004</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Ultimate Hitchhiker's Guide: Five Complete...</td>\n",
       "      <td>Douglas_Adams</td>\n",
       "      <td>4.38</td>\n",
       "      <td>eng</td>\n",
       "      <td>815</td>\n",
       "      <td>3628</td>\n",
       "      <td>254</td>\n",
       "      <td>Gramercy Books</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>The Supernaturalist</td>\n",
       "      <td>Eoin_Colfer</td>\n",
       "      <td>3.86</td>\n",
       "      <td>en-US</td>\n",
       "      <td>267</td>\n",
       "      <td>24863</td>\n",
       "      <td>1001</td>\n",
       "      <td>Disney-Hyperion</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11070</th>\n",
       "      <td>The Wish List</td>\n",
       "      <td>Eoin_Colfer</td>\n",
       "      <td>3.77</td>\n",
       "      <td>eng</td>\n",
       "      <td>252</td>\n",
       "      <td>13988</td>\n",
       "      <td>589</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2004</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>His Dark Materials (His Dark Materials  #1-3)</td>\n",
       "      <td>Philip_Pullman</td>\n",
       "      <td>4.26</td>\n",
       "      <td>eng</td>\n",
       "      <td>933</td>\n",
       "      <td>2656</td>\n",
       "      <td>260</td>\n",
       "      <td>Alfred A. Knopf</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2007</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>On the Road</td>\n",
       "      <td>Jack_Kerouac</td>\n",
       "      <td>3.63</td>\n",
       "      <td>en-US</td>\n",
       "      <td>307</td>\n",
       "      <td>3271</td>\n",
       "      <td>342</td>\n",
       "      <td>Penguin Classics</td>\n",
       "      <td>20th Century Fiction</td>\n",
       "      <td>2006</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109</th>\n",
       "      <td>Historia del rey transparente</td>\n",
       "      <td>Rosa_Montero</td>\n",
       "      <td>3.90</td>\n",
       "      <td>spa</td>\n",
       "      <td>592</td>\n",
       "      <td>1266</td>\n",
       "      <td>90</td>\n",
       "      <td>Punto de Lectura</td>\n",
       "      <td>Fantasy &amp; Science Fiction</td>\n",
       "      <td>2006</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title          author  \\\n",
       "0      Harry Potter and the Half-Blood Prince (Harry ...   J._K._Rowling   \n",
       "1      Harry Potter and the Order of the Phoenix (Har...   J._K._Rowling   \n",
       "2      Harry Potter and the Chamber of Secrets (Harry...   J._K._Rowling   \n",
       "3      Harry Potter and the Prisoner of Azkaban (Harr...   J._K._Rowling   \n",
       "7      The Ultimate Hitchhiker's Guide: Five Complete...   Douglas_Adams   \n",
       "...                                                  ...             ...   \n",
       "11069                                The Supernaturalist     Eoin_Colfer   \n",
       "11070                                      The Wish List     Eoin_Colfer   \n",
       "11085      His Dark Materials (His Dark Materials  #1-3)  Philip_Pullman   \n",
       "11100                                        On the Road    Jack_Kerouac   \n",
       "11109                      Historia del rey transparente    Rosa_Montero   \n",
       "\n",
       "       average_rating language_code  num-pages  ratings_count  \\\n",
       "0                4.57           eng        652        2095690   \n",
       "1                4.49           eng        870        2153167   \n",
       "2                4.42           eng        352           6333   \n",
       "3                4.56           eng        435        2339585   \n",
       "7                4.38           eng        815           3628   \n",
       "...               ...           ...        ...            ...   \n",
       "11069            3.86         en-US        267          24863   \n",
       "11070            3.77           eng        252          13988   \n",
       "11085            4.26           eng        933           2656   \n",
       "11100            3.63         en-US        307           3271   \n",
       "11109            3.90           spa        592           1266   \n",
       "\n",
       "       text_reviews_count         publisher                     genres years  \\\n",
       "0                   27591   Scholastic Inc.  Fantasy & Science Fiction  2006   \n",
       "1                   29221   Scholastic Inc.  Fantasy & Science Fiction  2004   \n",
       "2                     244        Scholastic  Fantasy & Science Fiction  2003   \n",
       "3                   36325   Scholastic Inc.  Fantasy & Science Fiction  2004   \n",
       "7                     254    Gramercy Books  Fantasy & Science Fiction  2005   \n",
       "...                   ...               ...                        ...   ...   \n",
       "11069                1001   Disney-Hyperion  Fantasy & Science Fiction  2005   \n",
       "11070                 589   Scholastic Inc.  Fantasy & Science Fiction  2004   \n",
       "11085                 260   Alfred A. Knopf  Fantasy & Science Fiction  2007   \n",
       "11100                 342  Penguin Classics       20th Century Fiction  2006   \n",
       "11109                  90  Punto de Lectura  Fantasy & Science Fiction  2006   \n",
       "\n",
       "      author_birthplace author_birthdate author_gender  \n",
       "0                  None             None          None  \n",
       "1                  None             None          None  \n",
       "2                  None             None          None  \n",
       "3                  None             None          None  \n",
       "7                  None             None          None  \n",
       "...                 ...              ...           ...  \n",
       "11069              None             None          None  \n",
       "11070              None             None          None  \n",
       "11085              None             None          None  \n",
       "11100              None             None          None  \n",
       "11109              None             None          None  \n",
       "\n",
       "[2902 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_before_webscraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f10ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_webscraping():\n",
    "    \n",
    "    lat_books = cleaning_before_webscraping()\n",
    "    \n",
    "    # Since it's almost Halloween, I'm going to create a new dataframe with only Horror novels.\n",
    "    horror_books = lat_books[lat_books['genres'] == 'Horror']\n",
    "    \n",
    "    # I'm going to keep only the horror novels that are better rated, above 3.9\n",
    "    horror_books = horror_books[horror_books['average_rating'] >= 3.9]\n",
    "    \n",
    "    def birthyear_f(string):\n",
    "        name = string\n",
    "        base_url = 'https://en.wikipedia.org/wiki'\n",
    "        endpoint = '/' + name\n",
    "        url = base_url + endpoint\n",
    "    \n",
    "        try:\n",
    "            res = requests.get(url)\n",
    "            res.raise_for_status()  # Check for request success\n",
    "            time.sleep(4)\n",
    "            soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        \n",
    "            # Attempt to find the birthplace information\n",
    "            birth_raw = soup.find(\"td\", {\"class\": \"infobox-data\"})\n",
    "        \n",
    "            if birth_raw is not None:\n",
    "                birth_info = birth_raw.getText().replace(\"(\", \"\\n\").replace(\")\", \"\\n\")\n",
    "                birth_info = re.sub(r'(\\d+)', r'\\1\\n', birth_info)\n",
    "                birth_list = birth_info.split('\\n')\n",
    "                birth_year = birth_list[1]\n",
    "                return birth_year\n",
    "            else:\n",
    "                return \"Birthyear information not found\"\n",
    "    \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return \"Error: Unable to fetch Wikipedia page\"\n",
    "        except Exception as e:\n",
    "            return \"An error occurred: \" + str(e)\n",
    "    \n",
    "    # Webscraping from Wikipedia with the above function to fill the 'author_birthdate' column.\n",
    "    horror_books['author_birthdate'] = horror_books['author'].apply(birthyear_f)\n",
    "    \n",
    "    def birthplace_f(string):\n",
    "        name = string\n",
    "        base_url = 'https://en.wikipedia.org/wiki'\n",
    "        endpoint = '/' + name\n",
    "        url = base_url + endpoint\n",
    "    \n",
    "        try:\n",
    "            res = requests.get(url)\n",
    "            res.raise_for_status()  # Check for request success\n",
    "            time.sleep(2)\n",
    "            soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        \n",
    "            # Attempt to find the birthplace information\n",
    "            birth_raw = soup.find(\"td\", {\"class\": \"infobox-data\"})\n",
    "        \n",
    "            if birth_raw is not None:\n",
    "                birth_info = birth_raw.getText().replace(\"(\", \"\\n\").replace(\")\", \"\\n\")\n",
    "                birth_info = re.sub(r'(\\d+)', r'\\1\\n', birth_info)\n",
    "                birth_list = birth_info.split('\\n')\n",
    "                birth_list[-1]\n",
    "                author_birthplace = birth_list[-1]\n",
    "                return author_birthplace\n",
    "            else:\n",
    "                return \"Birthplace information not found\"\n",
    "    \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return \"Error: Unable to fetch Wikipedia page\"\n",
    "        except Exception as e:\n",
    "            return \"An error occurred: \" + str(e)\n",
    "    \n",
    "    # Webscraping from Wikipedia with another function above to fill the 'author_birthplace' column.\n",
    "    horror_books['author_birthplace'] = horror_books['author'].apply(birthplace_f)\n",
    "    \n",
    "    def guess_gender_new(string):\n",
    "        # Instantiate the detector\n",
    "        d = gender_detector.Detector()\n",
    "        names = string.split('_')\n",
    "    \n",
    "        # Define a dictionary of specific names and genders\n",
    "        specific_names = {\n",
    "            'Wilkie_Collins': 'male',\n",
    "            'Raynold_Gideon': 'male',\n",
    "            'Laurell_K._Hamilton': 'female',\n",
    "            'C._S._Friedman': 'female',\n",
    "            'L._A._Banks': 'female',\n",
    "            'Tananarive_Due': 'female',\n",
    "            'V._C._Andrews': 'female',\n",
    "            'Sandy_Petersen': 'male',\n",
    "            'Mary_Higgins_Clark': 'female',\n",
    "            'Charlie_Huston': 'male',\n",
    "            'Natsuo_Kirino': 'female'\n",
    "        }\n",
    "    \n",
    "        # Check if the name is in the specific names dictionary\n",
    "        if string in specific_names:\n",
    "            return specific_names[string]\n",
    "        else:\n",
    "            first_name = names[0]\n",
    "            # Guess the gender\n",
    "            gender = d.get_gender(first_name)\n",
    "            return gender\n",
    "    \n",
    "    # With another function, I fill values from the 'author_gender' column.\n",
    "    horror_books['author_gender'] = horror_books['author'].apply(guess_gender_new)\n",
    "    \n",
    "    # I save my dataframe with the information from web scraping saved, just in case.\n",
    "\n",
    "    horror_books.to_csv(\"horror_books_2.csv\", index=False)\n",
    "\n",
    "    # Specify the folder path and filename for the CSV file\n",
    "    folder_path = \"/Users/usuari/Desktop/Ironhack/BOOTCAMP/projects/project-II/Data\"\n",
    "    file_name = \"horror_books_2.csv\"\n",
    "\n",
    "    # Combine the folder path and filename to create the full file path\n",
    "    full_file_path = f\"{folder_path}/{file_name}\"\n",
    "\n",
    "    # Export the DataFrame to the specified folder\n",
    "    horror_books.to_csv(full_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b938dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforming_webscraping()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
